{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c1a242ec-ecd4-47cc-b58c-8079f82e6f98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the best checkpoint file\n",
    "import glob\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b8d9afc5-69f1-4956-ada9-e02e25d547f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading the best model from: animals_classification_60_0.888.pth\n"
     ]
    }
   ],
   "source": [
    "list_of_files = glob.glob('animals_classification_*.pth')\n",
    "latest_file = max(list_of_files, key=os.path.getctime)\n",
    "print(f\"Loading the best model from: {latest_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fbbe95c4-7a78-4200-8359-45e2229361b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AnimalClassification(nn.Module):\n",
    "    def __init__(self, size_inner=256, droprate=0.2, num_classes=90):\n",
    "        super(AnimalClassification, self).__init__()\n",
    "\n",
    "        # Load pretrained ResNet18\n",
    "        self.base_model = models.resnet18(weights=\"IMAGENET1K_V1\")\n",
    "\n",
    "        # Freeze backbone\n",
    "        for param in self.base_model.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "        # Remove original FC layer\n",
    "        in_features = self.base_model.fc.in_features\n",
    "        self.base_model.fc = nn.Identity()\n",
    "\n",
    "        # Custom head\n",
    "        self.inner = nn.Linear(in_features, size_inner)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(droprate)\n",
    "        self.output_layer = nn.Linear(size_inner, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.base_model(x)          # (B, 512)\n",
    "        x = self.inner(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.output_layer(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c8e38944-a266-414c-adcf-304afe7d1b65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set up for using gpu to training\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "85c7d53b-e0b5-4bd3-a271-5ae53b0ab692",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AnimalClassification(\n",
       "  (base_model): ResNet(\n",
       "    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer4): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Identity()\n",
       "  )\n",
       "  (inner): Linear(in_features=512, out_features=256, bias=True)\n",
       "  (relu): ReLU()\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       "  (output_layer): Linear(in_features=256, out_features=90, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = AnimalClassification(size_inner=256, droprate=0.2, num_classes=90)\n",
    "model.load_state_dict(torch.load(latest_file))\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5a9d0cc1-f427-4ebe-8c58-35840a9d6594",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting onnx\n",
      "  Downloading onnx-1.20.0-cp312-abi3-win_amd64.whl.metadata (8.6 kB)\n",
      "Requirement already satisfied: numpy>=1.23.2 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from onnx) (2.3.4)\n",
      "Collecting protobuf>=4.25.1 (from onnx)\n",
      "  Downloading protobuf-6.33.2-cp310-abi3-win_amd64.whl.metadata (593 bytes)\n",
      "Requirement already satisfied: typing_extensions>=4.7.1 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from onnx) (4.15.0)\n",
      "Collecting ml_dtypes>=0.5.0 (from onnx)\n",
      "  Downloading ml_dtypes-0.5.4-cp312-cp312-win_amd64.whl.metadata (9.2 kB)\n",
      "Downloading onnx-1.20.0-cp312-abi3-win_amd64.whl (16.5 MB)\n",
      "   ---------------------------------------- 0.0/16.5 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.3/16.5 MB ? eta -:--:--\n",
      "   ------------------- -------------------- 7.9/16.5 MB 32.3 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 12.3/16.5 MB 27.5 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 16.0/16.5 MB 24.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 16.5/16.5 MB 22.6 MB/s  0:00:00\n",
      "Downloading ml_dtypes-0.5.4-cp312-cp312-win_amd64.whl (212 kB)\n",
      "Downloading protobuf-6.33.2-cp310-abi3-win_amd64.whl (436 kB)\n",
      "Installing collected packages: protobuf, ml_dtypes, onnx\n",
      "\n",
      "   ---------------------------------------- 0/3 [protobuf]\n",
      "   ---------------------------------------- 0/3 [protobuf]\n",
      "   ---------------------------------------- 0/3 [protobuf]\n",
      "   ---------------------------------------- 0/3 [protobuf]\n",
      "   ------------- -------------------------- 1/3 [ml_dtypes]\n",
      "   -------------------------- ------------- 2/3 [onnx]\n",
      "   -------------------------- ------------- 2/3 [onnx]\n",
      "   -------------------------- ------------- 2/3 [onnx]\n",
      "   -------------------------- ------------- 2/3 [onnx]\n",
      "   -------------------------- ------------- 2/3 [onnx]\n",
      "   -------------------------- ------------- 2/3 [onnx]\n",
      "   -------------------------- ------------- 2/3 [onnx]\n",
      "   -------------------------- ------------- 2/3 [onnx]\n",
      "   -------------------------- ------------- 2/3 [onnx]\n",
      "   -------------------------- ------------- 2/3 [onnx]\n",
      "   -------------------------- ------------- 2/3 [onnx]\n",
      "   -------------------------- ------------- 2/3 [onnx]\n",
      "   -------------------------- ------------- 2/3 [onnx]\n",
      "   -------------------------- ------------- 2/3 [onnx]\n",
      "   -------------------------- ------------- 2/3 [onnx]\n",
      "   -------------------------- ------------- 2/3 [onnx]\n",
      "   -------------------------- ------------- 2/3 [onnx]\n",
      "   -------------------------- ------------- 2/3 [onnx]\n",
      "   -------------------------- ------------- 2/3 [onnx]\n",
      "   -------------------------- ------------- 2/3 [onnx]\n",
      "   -------------------------- ------------- 2/3 [onnx]\n",
      "   -------------------------- ------------- 2/3 [onnx]\n",
      "   -------------------------- ------------- 2/3 [onnx]\n",
      "   -------------------------- ------------- 2/3 [onnx]\n",
      "   -------------------------- ------------- 2/3 [onnx]\n",
      "   -------------------------- ------------- 2/3 [onnx]\n",
      "   -------------------------- ------------- 2/3 [onnx]\n",
      "   -------------------------- ------------- 2/3 [onnx]\n",
      "   -------------------------- ------------- 2/3 [onnx]\n",
      "   -------------------------- ------------- 2/3 [onnx]\n",
      "   -------------------------- ------------- 2/3 [onnx]\n",
      "   -------------------------- ------------- 2/3 [onnx]\n",
      "   -------------------------- ------------- 2/3 [onnx]\n",
      "   -------------------------- ------------- 2/3 [onnx]\n",
      "   -------------------------- ------------- 2/3 [onnx]\n",
      "   -------------------------- ------------- 2/3 [onnx]\n",
      "   -------------------------- ------------- 2/3 [onnx]\n",
      "   -------------------------- ------------- 2/3 [onnx]\n",
      "   -------------------------- ------------- 2/3 [onnx]\n",
      "   -------------------------- ------------- 2/3 [onnx]\n",
      "   -------------------------- ------------- 2/3 [onnx]\n",
      "   -------------------------- ------------- 2/3 [onnx]\n",
      "   -------------------------- ------------- 2/3 [onnx]\n",
      "   -------------------------- ------------- 2/3 [onnx]\n",
      "   -------------------------- ------------- 2/3 [onnx]\n",
      "   -------------------------- ------------- 2/3 [onnx]\n",
      "   -------------------------- ------------- 2/3 [onnx]\n",
      "   -------------------------- ------------- 2/3 [onnx]\n",
      "   -------------------------- ------------- 2/3 [onnx]\n",
      "   -------------------------- ------------- 2/3 [onnx]\n",
      "   -------------------------- ------------- 2/3 [onnx]\n",
      "   -------------------------- ------------- 2/3 [onnx]\n",
      "   -------------------------- ------------- 2/3 [onnx]\n",
      "   -------------------------- ------------- 2/3 [onnx]\n",
      "   -------------------------- ------------- 2/3 [onnx]\n",
      "   -------------------------- ------------- 2/3 [onnx]\n",
      "   -------------------------- ------------- 2/3 [onnx]\n",
      "   -------------------------- ------------- 2/3 [onnx]\n",
      "   -------------------------- ------------- 2/3 [onnx]\n",
      "   -------------------------- ------------- 2/3 [onnx]\n",
      "   -------------------------- ------------- 2/3 [onnx]\n",
      "   -------------------------- ------------- 2/3 [onnx]\n",
      "   ---------------------------------------- 3/3 [onnx]\n",
      "\n",
      "Successfully installed ml_dtypes-0.5.4 onnx-1.20.0 protobuf-6.33.2\n"
     ]
    }
   ],
   "source": [
    "!pip install onnx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a91a5f17-429e-4df8-b59b-77d0d5ecdfaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model exported to animals_classification_latest.onnx\n"
     ]
    }
   ],
   "source": [
    "# Define dummy input for ONNX export\n",
    "# The input shape should match the input shape of your model (batch_size, channels, height, width)\n",
    "# Use a batch size of 1 for simplicity when exporting\n",
    "dummy_input = torch.randn(1, 3, 224, 224).to(device)\n",
    "\n",
    "# Export the model to ONNX format\n",
    "onnx_path = \"animals_classification_latest.onnx\"\n",
    "\n",
    "torch.onnx.export(\n",
    "    model,                     # PyTorch Model\n",
    "    dummy_input,               # Dummy input tensor\n",
    "    onnx_path,                 # Path to save the ONNX model\n",
    "    verbose=True,              # Print export details\n",
    "    input_names=['input'],     # Input layer name\n",
    "    output_names=['output'],   # Output layer name\n",
    "    dynamic_axes={             # Dynamic batch size\n",
    "        'input' : {0 : 'batch_size'},\n",
    "        'output' : {0 : 'batch_size'}\n",
    "    }\n",
    ")\n",
    "\n",
    "print(f\"Model exported to {onnx_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
